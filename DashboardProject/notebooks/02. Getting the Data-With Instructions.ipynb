{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data\n",
    "\n",
    "Our data comes directly from the [John Hopkins COVID-19 Github repository][1], which tracks all deaths and cases from each country in the world as well as many regions within some countries. All of the data needed for this project is within the [time series][2] directory, which contains four CSV files that summarize the deaths and cases for the world and the USA. The repository uses the word \"confirmed\" to refer to cases.\n",
    "\n",
    "[1]: https://github.com/CSSEGISandData/COVID-19\n",
    "[2]: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data into a pandas DataFrame\n",
    "\n",
    "The pandas `read_csv` function can read in remote CSV files by passing it the URL. The exact URL on Github is a bit tricky. You must use the \"raw\" data file, which can be retrieved by clicking on the file name (taking you to the next page), then right-clicking the \"view raw\" or \"download\" button and copying the link. The image below shows the screen you'll see for the first CSV.\n",
    "\n",
    "![1]\n",
    "\n",
    "[1]: images/url_download.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming conventions\n",
    "\n",
    "Before we write any code, let's cover some naming conventions that we will use throughout the project.\n",
    "\n",
    "### `group`\n",
    "\n",
    "We will use the name `group` to refer to the two separate \"groups\" of data.\n",
    "\n",
    "* `\"world\"` - represents all data from each country\n",
    "* `\"usa\"` - represents all data from each US state\n",
    "\n",
    "### `kind`\n",
    "\n",
    "We will use the name `kind` to refer to the two different kinds of COVID-19 data.\n",
    "\n",
    "* `\"deaths\"`\n",
    "* `\"cases\"`\n",
    "\n",
    "\n",
    "### `area`\n",
    "\n",
    "Occasionally, we will refer to either a specific country or state with the name `area`.\n",
    "\n",
    "## Downloading the data\n",
    "\n",
    "Now that we have the URL, we can download the data with pandas. Complete the exercise below to download all four files as DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that reads in a single CSV and returns it as a DataFrame. This function accepts a kind and group. Use the variable `DOWNLOAD_URL` in your solution. Make sure you look at the URL in the repo from above to determine what values `kind` and `group` refer to. You'll have to reassign their values in the function so that the URL is correct. For example, the function call `download_data(\"world\", \"deaths\")` should download [one of the files on this page](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DOWNLOAD_URL = (\n",
    "    \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/\"\n",
    "    \"master/csse_covid_19_data/csse_covid_19_time_series/\"\n",
    "    \"time_series_covid19_{kind}_{group}.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "def download_data(group, kind):\n",
    "    \"\"\"\n",
    "    Reads in a single dataset from the John Hopkins GitHub repo\n",
    "    as a DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group : \"world\" or \"usa\"\n",
    "    \n",
    "    kind : \"deaths\" or \"cases\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    group = \"US\" if group == \"usa\" else \"global\"\n",
    "    kind = \"confirmed\" if kind == \"cases\" else \"deaths\"\n",
    "    url = DOWNLOAD_URL.format(kind=kind, group=group)\n",
    "    return pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>2/19/22</th>\n",
       "      <th>2/20/22</th>\n",
       "      <th>2/21/22</th>\n",
       "      <th>2/22/22</th>\n",
       "      <th>2/23/22</th>\n",
       "      <th>2/24/22</th>\n",
       "      <th>2/25/22</th>\n",
       "      <th>2/26/22</th>\n",
       "      <th>2/27/22</th>\n",
       "      <th>2/28/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>192</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>636</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84001007</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84001009</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>...</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>217</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "3  84001007   US  USA    840  1007.0     Bibb        Alabama             US   \n",
       "4  84001009   US  USA    840  1009.0   Blount        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 2/19/22  2/20/22  2/21/22  2/22/22  2/23/22  \\\n",
       "0  32.539527 -86.644082  ...     184      184      184      184      184   \n",
       "1  30.727750 -87.722071  ...     635      635      635      635      636   \n",
       "2  31.868263 -85.387129  ...      92       92       92       92       92   \n",
       "3  32.996421 -87.125115  ...      99       99       99       99       99   \n",
       "4  33.982109 -86.567906  ...     216      216      216      216      216   \n",
       "\n",
       "   2/24/22  2/25/22  2/26/22  2/27/22  2/28/22  \n",
       "0      192      194      194      194      194  \n",
       "1      640      640      640      640      640  \n",
       "2       92       93       93       93       93  \n",
       "3       99       99       99       99       99  \n",
       "4      216      217      218      218      218  \n",
       "\n",
       "[5 rows x 781 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_deaths = download_data('usa', 'deaths')\n",
    "usa_deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important information on exercises - please read!\n",
    "\n",
    "All of the exercises require you to complete the body of a function. All functions end with the `pass` keyword. **Delete** it and write your solution in the body of the function.\n",
    "\n",
    "Solutions for all exercises are found in the [solutions.py](solutions.py) file in this directory. You can open it up in your favorite editor, or just click the link to open it in your browser.\n",
    "\n",
    "In the code cell following each exercise, you will see a single line of code that imports the function from the solutions.py file. For example, `from solutions import download_data`. Running this statement will provide you with a version of the function that produces the correct output for the exercise.\n",
    "\n",
    "**Comment out the import line** if you want to use and test **your version** of the function completed above. I highly recommend completing the exercises on your own. Keep the import line uncommented if you do not attempt the exercise. \n",
    "\n",
    "**Always check the solutions!** Make sure to check the [solutions.py](solutions.py) file for each exercise, even if you are sure you answered it correctly. Verifying solutions is one of the best known methods for internalizing new material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the `download_data` function\n",
    "\n",
    "Let's read in the world deaths file as a DataFrame and output the head to verify that it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out the import line below if you attempted the exercise above\n",
    "# keep the line below if you did not attempt the exercise\n",
    "from solutions import download_data \n",
    "df_world_deaths = download_data('world', 'deaths')\n",
    "df_world_deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a another function which uses `download_data` to read in all four DataFrames.\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that reads in all four CSVs as DataFrames returning them in a dictionary. Use the group and kind separated by an underscore as the key (i.e. `\"world_deaths\"`). Use the `GROUPS` and `KINDS` variables in your solution.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = \"world\", \"usa\"\n",
    "KINDS = \"deaths\", \"cases\"\n",
    "\n",
    "def read_all_data():\n",
    "    \"\"\"\n",
    "    Read in all four CSVs as DataFrames\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for group in GROUPS:\n",
    "        for kind in KINDS:\n",
    "            data[f'{group}_{kind}'] = download_data(group, kind)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/19/22</th>\n",
       "      <th>2/20/22</th>\n",
       "      <th>2/21/22</th>\n",
       "      <th>2/22/22</th>\n",
       "      <th>2/23/22</th>\n",
       "      <th>2/24/22</th>\n",
       "      <th>2/25/22</th>\n",
       "      <th>2/26/22</th>\n",
       "      <th>2/27/22</th>\n",
       "      <th>2/28/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>171931</td>\n",
       "      <td>172205</td>\n",
       "      <td>172441</td>\n",
       "      <td>172716</td>\n",
       "      <td>172901</td>\n",
       "      <td>173047</td>\n",
       "      <td>173084</td>\n",
       "      <td>173146</td>\n",
       "      <td>173395</td>\n",
       "      <td>173659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>269904</td>\n",
       "      <td>270164</td>\n",
       "      <td>270370</td>\n",
       "      <td>270455</td>\n",
       "      <td>270734</td>\n",
       "      <td>270947</td>\n",
       "      <td>271141</td>\n",
       "      <td>271141</td>\n",
       "      <td>271527</td>\n",
       "      <td>271563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>263936</td>\n",
       "      <td>264054</td>\n",
       "      <td>264201</td>\n",
       "      <td>264365</td>\n",
       "      <td>264488</td>\n",
       "      <td>264603</td>\n",
       "      <td>264706</td>\n",
       "      <td>264778</td>\n",
       "      <td>264855</td>\n",
       "      <td>264936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37589</td>\n",
       "      <td>37589</td>\n",
       "      <td>37589</td>\n",
       "      <td>37820</td>\n",
       "      <td>37901</td>\n",
       "      <td>37958</td>\n",
       "      <td>37999</td>\n",
       "      <td>37999</td>\n",
       "      <td>37999</td>\n",
       "      <td>37999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>98617</td>\n",
       "      <td>98638</td>\n",
       "      <td>98658</td>\n",
       "      <td>98671</td>\n",
       "      <td>98698</td>\n",
       "      <td>98701</td>\n",
       "      <td>98701</td>\n",
       "      <td>98701</td>\n",
       "      <td>98701</td>\n",
       "      <td>98741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/19/22  2/20/22  2/21/22  \\\n",
       "0        0        0        0        0  ...   171931   172205   172441   \n",
       "1        0        0        0        0  ...   269904   270164   270370   \n",
       "2        0        0        0        0  ...   263936   264054   264201   \n",
       "3        0        0        0        0  ...    37589    37589    37589   \n",
       "4        0        0        0        0  ...    98617    98638    98658   \n",
       "\n",
       "   2/22/22  2/23/22  2/24/22  2/25/22  2/26/22  2/27/22  2/28/22  \n",
       "0   172716   172901   173047   173084   173146   173395   173659  \n",
       "1   270455   270734   270947   271141   271141   271527   271563  \n",
       "2   264365   264488   264603   264706   264778   264855   264936  \n",
       "3    37820    37901    37958    37999    37999    37999    37999  \n",
       "4    98671    98698    98701    98701    98701    98701    98741  \n",
       "\n",
       "[5 rows x 773 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['usa_cases'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>2/19/22</th>\n",
       "      <th>2/20/22</th>\n",
       "      <th>2/21/22</th>\n",
       "      <th>2/22/22</th>\n",
       "      <th>2/23/22</th>\n",
       "      <th>2/24/22</th>\n",
       "      <th>2/25/22</th>\n",
       "      <th>2/26/22</th>\n",
       "      <th>2/27/22</th>\n",
       "      <th>2/28/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>192</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>636</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84001007</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84001009</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>...</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>217</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "3  84001007   US  USA    840  1007.0     Bibb        Alabama             US   \n",
       "4  84001009   US  USA    840  1009.0   Blount        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 2/19/22  2/20/22  2/21/22  2/22/22  2/23/22  \\\n",
       "0  32.539527 -86.644082  ...     184      184      184      184      184   \n",
       "1  30.727750 -87.722071  ...     635      635      635      635      636   \n",
       "2  31.868263 -85.387129  ...      92       92       92       92       92   \n",
       "3  32.996421 -87.125115  ...      99       99       99       99       99   \n",
       "4  33.982109 -86.567906  ...     216      216      216      216      216   \n",
       "\n",
       "   2/24/22  2/25/22  2/26/22  2/27/22  2/28/22  \n",
       "0      192      194      194      194      194  \n",
       "1      640      640      640      640      640  \n",
       "2       92       93       93       93       93  \n",
       "3       99       99       99       99       99  \n",
       "4      216      217      218      218      218  \n",
       "\n",
       "[5 rows x 781 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['usa_deaths'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to read in all of the data and output the head of two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to comment out the following line if you attempt the exercise\n",
    "# this is the last exercise with this warning\n",
    "from solutions import read_all_data\n",
    "data = read_all_data()\n",
    "data['world_cases'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['usa_cases'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data locally\n",
    "\n",
    "Since the raw data must be downloaded from the internet, let's save a copy of our current data to a local folder so that we have access to it immediately at any time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that accepts a dictionary of DataFrames and a directory name, and writes them to that directory as CSVs using the key as the filename. Pass the `kwargs` to the `to_csv` method.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data, directory, **kwargs):\n",
    "    \"\"\"\n",
    "    Writes each raw data DataFrame to a file as a CSV\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dictionary of DataFrames\n",
    "\n",
    "    directory : string name of directory to save files i.e. \"data/raw\"\n",
    "    \n",
    "    kwargs : extra keyword arguments for the `to_csv` DataFrame method\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for name, df in data.items():\n",
    "        df.to_csv(f'{directory}/{name}.csv', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data(data, 'data/raw', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write those DataFrames as CSVs (without their index) to the \"data/raw\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions import write_data\n",
    "write_data(data, \"data/raw\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function similar to `download_data`, but have it read in the local data that we just saved. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_local_data(group, kind, directory):\n",
    "    \"\"\"\n",
    "    Read in one CSV as a DataFrame from the given directory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group : \"world\" or \"usa\"\n",
    "    \n",
    "    kind : \"deaths\" or \"cases\"\n",
    "    \n",
    "    directory : string name of directory to save files i.e. \"data/raw\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame    \n",
    "    \"\"\"\n",
    "    return pd.read_csv(f'{directory}/{group}_{kind}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_cases = read_local_data('usa', 'cases', 'data/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>2/19/22</th>\n",
       "      <th>2/20/22</th>\n",
       "      <th>2/21/22</th>\n",
       "      <th>2/22/22</th>\n",
       "      <th>2/23/22</th>\n",
       "      <th>2/24/22</th>\n",
       "      <th>2/25/22</th>\n",
       "      <th>2/26/22</th>\n",
       "      <th>2/27/22</th>\n",
       "      <th>2/28/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>15420</td>\n",
       "      <td>15431</td>\n",
       "      <td>15436</td>\n",
       "      <td>15442</td>\n",
       "      <td>15451</td>\n",
       "      <td>15468</td>\n",
       "      <td>15479</td>\n",
       "      <td>15503</td>\n",
       "      <td>15509</td>\n",
       "      <td>15510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>54734</td>\n",
       "      <td>54763</td>\n",
       "      <td>54784</td>\n",
       "      <td>54805</td>\n",
       "      <td>54837</td>\n",
       "      <td>54874</td>\n",
       "      <td>54904</td>\n",
       "      <td>54957</td>\n",
       "      <td>54972</td>\n",
       "      <td>54978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>5426</td>\n",
       "      <td>5429</td>\n",
       "      <td>5429</td>\n",
       "      <td>5430</td>\n",
       "      <td>5433</td>\n",
       "      <td>5436</td>\n",
       "      <td>5438</td>\n",
       "      <td>5440</td>\n",
       "      <td>5445</td>\n",
       "      <td>5445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84001007</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>...</td>\n",
       "      <td>6351</td>\n",
       "      <td>6354</td>\n",
       "      <td>6355</td>\n",
       "      <td>6360</td>\n",
       "      <td>6364</td>\n",
       "      <td>6367</td>\n",
       "      <td>6369</td>\n",
       "      <td>6374</td>\n",
       "      <td>6375</td>\n",
       "      <td>6375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84001009</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>...</td>\n",
       "      <td>14663</td>\n",
       "      <td>14672</td>\n",
       "      <td>14682</td>\n",
       "      <td>14688</td>\n",
       "      <td>14706</td>\n",
       "      <td>14710</td>\n",
       "      <td>14734</td>\n",
       "      <td>14753</td>\n",
       "      <td>14757</td>\n",
       "      <td>14760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "3  84001007   US  USA    840  1007.0     Bibb        Alabama             US   \n",
       "4  84001009   US  USA    840  1009.0   Blount        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 2/19/22  2/20/22  2/21/22  2/22/22  2/23/22  \\\n",
       "0  32.539527 -86.644082  ...   15420    15431    15436    15442    15451   \n",
       "1  30.727750 -87.722071  ...   54734    54763    54784    54805    54837   \n",
       "2  31.868263 -85.387129  ...    5426     5429     5429     5430     5433   \n",
       "3  32.996421 -87.125115  ...    6351     6354     6355     6360     6364   \n",
       "4  33.982109 -86.567906  ...   14663    14672    14682    14688    14706   \n",
       "\n",
       "   2/24/22  2/25/22  2/26/22  2/27/22  2/28/22  \n",
       "0    15468    15479    15503    15509    15510  \n",
       "1    54874    54904    54957    54972    54978  \n",
       "2     5436     5438     5440     5445     5445  \n",
       "3     6367     6369     6374     6375     6375  \n",
       "4    14710    14734    14753    14757    14760  \n",
       "\n",
       "[5 rows x 780 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions import read_local_data\n",
    "read_local_data('world', 'deaths', 'data/raw').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function similar to `read_all_data`, but have it read in all of the local data that we just saved. The function name is `run` since we will be slowly adding all of our data cleaning and transformation steps to it in the next chapter.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = \"world\", \"usa\"\n",
    "KINDS = \"deaths\", \"cases\"\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Run all cleaning and transformation steps\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for group in GROUPS:\n",
    "        for kind in KINDS:\n",
    "            data[f'{group}_{kind}'] = read_local_data(group, kind, 'data/raw')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>2/19/22</th>\n",
       "      <th>2/20/22</th>\n",
       "      <th>2/21/22</th>\n",
       "      <th>2/22/22</th>\n",
       "      <th>2/23/22</th>\n",
       "      <th>2/24/22</th>\n",
       "      <th>2/25/22</th>\n",
       "      <th>2/26/22</th>\n",
       "      <th>2/27/22</th>\n",
       "      <th>2/28/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>192</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "      <td>636</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84001007</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84001009</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>...</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>217</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>84056039</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>56039.0</td>\n",
       "      <td>Teton</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>43.935225</td>\n",
       "      <td>-110.589080</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>84056041</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>56041.0</td>\n",
       "      <td>Uinta</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>41.287818</td>\n",
       "      <td>-110.547578</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>84090056</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>90056.0</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>84056043</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>43.904516</td>\n",
       "      <td>-107.680187</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>84056045</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>56045.0</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>43.839612</td>\n",
       "      <td>-104.567488</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3342 rows Ã— 781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           UID iso2 iso3  code3     FIPS      Admin2 Province_State  \\\n",
       "0     84001001   US  USA    840   1001.0     Autauga        Alabama   \n",
       "1     84001003   US  USA    840   1003.0     Baldwin        Alabama   \n",
       "2     84001005   US  USA    840   1005.0     Barbour        Alabama   \n",
       "3     84001007   US  USA    840   1007.0        Bibb        Alabama   \n",
       "4     84001009   US  USA    840   1009.0      Blount        Alabama   \n",
       "...        ...  ...  ...    ...      ...         ...            ...   \n",
       "3337  84056039   US  USA    840  56039.0       Teton        Wyoming   \n",
       "3338  84056041   US  USA    840  56041.0       Uinta        Wyoming   \n",
       "3339  84090056   US  USA    840  90056.0  Unassigned        Wyoming   \n",
       "3340  84056043   US  USA    840  56043.0    Washakie        Wyoming   \n",
       "3341  84056045   US  USA    840  56045.0      Weston        Wyoming   \n",
       "\n",
       "     Country_Region        Lat       Long_  ... 2/19/22  2/20/22  2/21/22  \\\n",
       "0                US  32.539527  -86.644082  ...     184      184      184   \n",
       "1                US  30.727750  -87.722071  ...     635      635      635   \n",
       "2                US  31.868263  -85.387129  ...      92       92       92   \n",
       "3                US  32.996421  -87.125115  ...      99       99       99   \n",
       "4                US  33.982109  -86.567906  ...     216      216      216   \n",
       "...             ...        ...         ...  ...     ...      ...      ...   \n",
       "3337             US  43.935225 -110.589080  ...      15       15       15   \n",
       "3338             US  41.287818 -110.547578  ...      36       36       36   \n",
       "3339             US   0.000000    0.000000  ...       0        0        0   \n",
       "3340             US  43.904516 -107.680187  ...      42       42       42   \n",
       "3341             US  43.839612 -104.567488  ...      17       17       17   \n",
       "\n",
       "      2/22/22  2/23/22  2/24/22  2/25/22  2/26/22  2/27/22  2/28/22  \n",
       "0         184      184      192      194      194      194      194  \n",
       "1         635      636      640      640      640      640      640  \n",
       "2          92       92       92       93       93       93       93  \n",
       "3          99       99       99       99       99       99       99  \n",
       "4         216      216      216      217      218      218      218  \n",
       "...       ...      ...      ...      ...      ...      ...      ...  \n",
       "3337       16       16       16       16       16       16       16  \n",
       "3338       36       36       36       36       36       36       36  \n",
       "3339        0        0        0        0        0        0       18  \n",
       "3340       43       43       43       43       43       43       43  \n",
       "3341       18       18       18       18       18       18       18  \n",
       "\n",
       "[3342 rows x 781 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['usa_deaths']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we verify that `run` works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions import run\n",
    "data = run()\n",
    "data['usa_deaths'].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the section on downloading the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

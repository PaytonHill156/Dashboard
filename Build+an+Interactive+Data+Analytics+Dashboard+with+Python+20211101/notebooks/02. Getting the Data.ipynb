{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data\n",
    "\n",
    "Our data comes directly from the [John Hopkins COVID-19 Github repository][1], which tracks all deaths and cases from each country in the world as well as many regions within some countries. All of the data needed for this project is within the [time series][2] directory, which contains four CSV files that summarize the deaths and cases for the world and the USA. The repository uses the word \"confirmed\" to refer to cases.\n",
    "\n",
    "[1]: https://github.com/CSSEGISandData/COVID-19\n",
    "[2]: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data into a pandas DataFrame\n",
    "\n",
    "The pandas `read_csv` function can read in remote CSV files by passing it the URL. The exact URL on Github is a bit tricky. You must use the \"raw\" data file, which can be retrieved by clicking on the file name (taking you to the next page), then right-clicking the \"view raw\" or \"download\" button and copying the link. The image below shows the screen you'll see for the first CSV.\n",
    "\n",
    "![1]\n",
    "\n",
    "[1]: images/url_download.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming conventions\n",
    "\n",
    "Before we write any code, let's cover some naming conventions that we will use throughout the project.\n",
    "\n",
    "### `group`\n",
    "\n",
    "We will use the name `group` to refer to the two separate \"groups\" of data.\n",
    "\n",
    "* `\"world\"` - represents all data from each country\n",
    "* `\"usa\"` - represents all data from each US state\n",
    "\n",
    "### `kind`\n",
    "\n",
    "We will use the name `kind` to refer to the two different kinds of COVID-19 data.\n",
    "\n",
    "* `\"deaths\"`\n",
    "* `\"cases\"`\n",
    "\n",
    "\n",
    "### `area`\n",
    "\n",
    "Occasionally, we will refer to either a specific country or state with the name `area`.\n",
    "\n",
    "## Downloading the data\n",
    "\n",
    "Now that we have the URL, we can download the data with pandas. Complete the exercise below to download all four files as DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that reads in a single CSV and returns it as a DataFrame. This function accepts a kind and group. Use the variable `DOWNLOAD_URL` in your solution. Make sure you look at the URL in the repo from above to determine what values `kind` and `group` refer to. You'll have to reassign their values in the function so that the URL is correct. For example, the function call `download_data(\"world\", \"deaths\")` should download [one of the files on this page](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DOWNLOAD_URL = (\n",
    "    \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/\"\n",
    "    \"master/csse_covid_19_data/csse_covid_19_time_series/\"\n",
    "    \"time_series_covid19_{kind}_{group}.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "def download_data(group, kind):\n",
    "    \"\"\"\n",
    "    Reads in a single dataset from the John Hopkins GitHub repo\n",
    "    as a DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group : \"world\" or \"usa\"\n",
    "    \n",
    "    kind : \"deaths\" or \"cases\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important information on exercises - please read!\n",
    "\n",
    "All of the exercises require you to complete the body of a function. All functions end with the `pass` keyword. **Delete** it and write your solution in the body of the function.\n",
    "\n",
    "Solutions for all exercises are found in the [solutions.py](solutions.py) file in this directory. You can open it up in your favorite editor, or just click the link to open it in your browser.\n",
    "\n",
    "In the code cell following each exercise, you will see a single line of code that imports the function from the solutions.py file. For example, `from solutions import download_data`. Running this statement will provide you with a version of the function that produces the correct output for the exercise.\n",
    "\n",
    "**Comment out the import line** if you want to use and test **your version** of the function completed above. I highly recommend completing the exercises on your own. Keep the import line uncommented if you do not attempt the exercise. \n",
    "\n",
    "**Always check the solutions!** Make sure to check the [solutions.py](solutions.py) file for each exercise, even if you are sure you answered it correctly. Verifying solutions is one of the best known methods for internalizing new material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the `download_data` function\n",
    "\n",
    "Let's read in the world deaths file as a DataFrame and output the head to verify that it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out the import line below if you attempted the exercise above\n",
    "# keep the line below if you did not attempt the exercise\n",
    "from solutions import download_data \n",
    "df_world_deaths = download_data('world', 'deaths')\n",
    "df_world_deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a another function which uses `download_data` to read in all four DataFrames.\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that reads in all four CSVs as DataFrames returning them in a dictionary. Use the group and kind separated by an underscore as the key (i.e. `\"world_deaths\"`). Use the `GROUPS` and `KINDS` variables in your solution.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = \"world\", \"usa\"\n",
    "KINDS = \"deaths\", \"cases\"\n",
    "\n",
    "def read_all_data():\n",
    "    \"\"\"\n",
    "    Read in all four CSVs as DataFrames\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to read in all of the data and output the head of two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to comment out the following line if you attempt the exercise\n",
    "# this is the last exercise with this warning\n",
    "from solutions import read_all_data\n",
    "data = read_all_data()\n",
    "data['world_cases'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['usa_cases'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data locally\n",
    "\n",
    "Since the raw data must be downloaded from the internet, let's save a copy of our current data to a local folder so that we have access to it immediately at any time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that accepts a dictionary of DataFrames and a directory name, and writes them to that directory as CSVs using the key as the filename. Pass the `kwargs` to the `to_csv` method.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data, directory, **kwargs):\n",
    "    \"\"\"\n",
    "    Writes each raw data DataFrame to a file as a CSV\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dictionary of DataFrames\n",
    "\n",
    "    directory : string name of directory to save files i.e. \"data/raw\"\n",
    "    \n",
    "    kwargs : extra keyword arguments for the `to_csv` DataFrame method\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write those DataFrames as CSVs (without their index) to the \"data/raw\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions import write_data\n",
    "write_data(data, \"data/raw\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function similar to `download_data`, but have it read in the local data that we just saved. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_local_data(group, kind, directory):\n",
    "    \"\"\"\n",
    "    Read in one CSV as a DataFrame from the given directory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group : \"world\" or \"usa\"\n",
    "    \n",
    "    kind : \"deaths\" or \"cases\"\n",
    "    \n",
    "    directory : string name of directory to save files i.e. \"data/raw\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions import read_local_data\n",
    "read_local_data('world', 'deaths', 'data/raw').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function similar to `read_all_data`, but have it read in all of the local data that we just saved. The function name is `run` since we will be slowly adding all of our data cleaning and transformation steps to it in the next chapter.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \"\"\"\n",
    "    Run all cleaning and transformation steps\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we verify that `run` works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions import run\n",
    "data = run()\n",
    "data['usa_deaths'].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the section on downloading the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
